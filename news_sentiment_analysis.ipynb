{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "news_sentiment analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjalinagel12/Google-colab-notebook/blob/master/news_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To9ENLU90WGl",
        "colab_type": "code",
        "outputId": "9b7e6f42-3066-4b0d-ad49-a9f36ce8732e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n",
            "\r\u001b[K     |▊                               | 10kB 32.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |███                             | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 92kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 450kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.47)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 19.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.47)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=76c9c0d36e79858f3a6a684478d6b4fe35dfa0a3c03bbdf84478aa92253d4f8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 transformers-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvFvBLJV0Dkv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "cfa227a0-9dba-4b37-ea4c-c4d65ead830d"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ-42fh0hjsF",
        "colab_type": "text"
      },
      "source": [
        "## Importing the dataset\n",
        "We'll use pandas to read the dataset and load it into a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfCTRWMt6Qwa",
        "colab_type": "code",
        "outputId": "ef051e0d-2a6a-4130-8a13-ad433789d1ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxhFgpyGCv-p",
        "colab_type": "code",
        "outputId": "72f1e355-854e-46d4-ad14-2a54931814b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/ZS/input/dataset/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ZS/input/dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTFv0VlSCwCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/ZS/input/dataset/train_file.csv', sep=\",\")\n",
        "#df.tail(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTQqQ5CgHj-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XtXYoERdymz",
        "colab_type": "text"
      },
      "source": [
        "#Sentiment Headline prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f77mLQrzCwGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_total = df[['Headline', 'SentimentHeadline']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTM3hOHW4hUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_1 = batch_total[:2000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KMWFoaPJqyyh"
      },
      "source": [
        "## Loading the Pre-trained BERT model\n",
        "Let's now load a pre-trained BERT model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1X8y7dj5qyyf",
        "colab": {}
      },
      "source": [
        "# For DistilBERT:\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "## Want BERT instead of distilBERT? Uncomment the following line:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "'''\n",
        "# Transformers has a unified API\n",
        "# for 10 transformer architectures and 30 pretrained weights.\n",
        "#          Model          | Tokenizer          | Pretrained weights shortcut\n",
        "MODELS = [(BertModel,       BertTokenizer,       'bert-base-uncased'),\n",
        "          (OpenAIGPTModel,  OpenAIGPTTokenizer,  'openai-gpt'),\n",
        "          (GPT2Model,       GPT2Tokenizer,       'gpt2'),\n",
        "          (CTRLModel,       CTRLTokenizer,       'ctrl'),\n",
        "          (TransfoXLModel,  TransfoXLTokenizer,  'transfo-xl-wt103'),\n",
        "          (XLNetModel,      XLNetTokenizer,      'xlnet-base-cased'),\n",
        "          (XLMModel,        XLMTokenizer,        'xlm-mlm-enfr-1024'),\n",
        "          (DistilBertModel, DistilBertTokenizer, 'distilbert-base-uncased'),\n",
        "          (RobertaModel,    RobertaTokenizer,    'roberta-base'),\n",
        "          (XLMRobertaModel, XLMRobertaTokenizer, 'xlm-roberta-base'),\n",
        "         ]\n",
        "\n",
        "# To use TensorFlow 2.0 versions of the models, simply prefix the class names with 'TF', e.g. `TFRobertaModel` is the TF 2.0 counterpart of the PyTorch model `RobertaModel`\n",
        "\n",
        "# Each architecture is provided with several class for fine-tuning on down-stream tasks, e.g.\n",
        "BERT_MODEL_CLASSES = [BertModel, BertForPreTraining, BertForMaskedLM, BertForNextSentencePrediction,\n",
        "                      BertForSequenceClassification, BertForTokenClassification, BertForQuestionAnswering]\n",
        "\n",
        "# All the classes for an architecture can be initiated from pretrained weights for this architecture\n",
        "# Note that additional weights added for fine-tuning are only initialized\n",
        "'''\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O38Juxdtqyye"
      },
      "source": [
        "Right now, the variable `model` holds a pretrained distilBERT model -- a version of BERT that is smaller, but much faster and requiring a lot less memory.\n",
        "\n",
        "## Model #1: Preparing the Dataset\n",
        "Before we can hand our sentences to BERT, we need to so some minimal processing to put them in the format it requires.\n",
        "\n",
        "### Tokenization\n",
        "Our first step is to tokenize the sentences -- break them up into word and subwords in the format BERT is comfortable with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BovcU9o3qyyd"
      },
      "source": [
        "##tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xnmd4XX3qyyb",
        "colab": {}
      },
      "source": [
        "tokenized = batch_1['Headline'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MKGc7lxyqyyW",
        "colab": {}
      },
      "source": [
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "#max_len = max(max_len,66) # to make it more understandable as our iamges have tokens of length 66\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TUIFgxOXqyyV"
      },
      "source": [
        "Our dataset is now in the `padded` variable, we can view its dimensions below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PbgHfvF6qyyT",
        "outputId": "faa18dd0-c26b-4ba2-95fa-7b53d047100b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(padded).shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 121)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI0zHKF5Mzf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQSyEbLVMzpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJXoOAjnMSAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "## Want BERT instead of distilBERT? Uncomment the following line:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "'''\n",
        "# Transformers has a unified API\n",
        "# for 10 transformer architectures and 30 pretrained weights.\n",
        "#          Model          | Tokenizer          | Pretrained weights shortcut\n",
        "MODELS = [(BertModel,       BertTokenizer,       'bert-base-uncased'),\n",
        "          (OpenAIGPTModel,  OpenAIGPTTokenizer,  'openai-gpt'),\n",
        "          (GPT2Model,       GPT2Tokenizer,       'gpt2'),\n",
        "          (CTRLModel,       CTRLTokenizer,       'ctrl'),\n",
        "          (TransfoXLModel,  TransfoXLTokenizer,  'transfo-xl-wt103'),\n",
        "          (XLNetModel,      XLNetTokenizer,      'xlnet-base-cased'),\n",
        "          (XLMModel,        XLMTokenizer,        'xlm-mlm-enfr-1024'),\n",
        "          (DistilBertModel, DistilBertTokenizer, 'distilbert-base-uncased'),\n",
        "          (RobertaModel,    RobertaTokenizer,    'roberta-base'),\n",
        "          (XLMRobertaModel, XLMRobertaTokenizer, 'xlm-roberta-base'),\n",
        "         ]\n",
        "\n",
        "# To use TensorFlow 2.0 versions of the models, simply prefix the class names with 'TF', e.g. `TFRobertaModel` is the TF 2.0 counterpart of the PyTorch model `RobertaModel`\n",
        "\n",
        "# Each architecture is provided with several class for fine-tuning on down-stream tasks, e.g.\n",
        "BERT_MODEL_CLASSES = [BertModel, BertForPreTraining, BertForMaskedLM, BertForNextSentencePrediction,\n",
        "                      BertForSequenceClassification, BertForTokenClassification, BertForQuestionAnswering]\n",
        "\n",
        "# All the classes for an architecture can be initiated from pretrained weights for this architecture\n",
        "# Note that additional weights added for fine-tuning are only initialized\n",
        "'''\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoGERnWUHjw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = pd.read_csv('/content/drive/My Drive/ZS/input/dataset/test_file.csv', sep=\",\")\n",
        "#df_test.tail(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW1ZqeH_HvcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_total_test = df_test[['Headline','IDLink']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE4XrUuTfUOp",
        "colab_type": "code",
        "outputId": "4bcb223a-83ce-4d31-8d3d-84c6090bacfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(batch_total_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37288"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MrNVNfAHvfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_1_test = batch_total_test[:1000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnGaH3dQIGHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_test = batch_1_test['Headline'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB_KicuCIO1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 0\n",
        "for i in tokenized_test.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "#max_len = max(max_len,66) # to make it more understandable as our iamges have tokens of length 66\n",
        "padded_test = np.array([i + [0]*(max_len-len(i)) for i in tokenized_test.values])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32xdt7b2IaWG",
        "colab_type": "code",
        "outputId": "eee40f56-71da-4232-d411-c5c886b59de1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(padded_test).shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 156)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JofrWf5VqyyT"
      },
      "source": [
        "### Masking\n",
        "If we directly send `padded` to BERT, that would slightly confuse it. We need to create another variable to tell it to ignore (mask) the padding we've added when it's processing its input. That's what attention_mask is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qblTTK9CqyyQ",
        "outputId": "13efc81a-508e-44ca-b06d-f56bf82bb9a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 121)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xh93F5pmTd3B",
        "colab_type": "code",
        "outputId": "1f31ff81-73dc-4811-976b-748d03717605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "attention_mask_test = np.where(padded_test != 0, 1, 0)\n",
        "attention_mask_test.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 156)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Brk88Ji2qyyO",
        "colab": {}
      },
      "source": [
        "input_ids = torch.tensor(padded)  \n",
        "attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdKpWA27TmaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids_test = torch.tensor(padded_test)  \n",
        "attention_mask_test = torch.tensor(attention_mask_test)\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states_test = model(input_ids_test, attention_mask=attention_mask_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1TEtoiuEqyyL",
        "colab": {}
      },
      "source": [
        "features = last_hidden_states[0][:,0,:].numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4m16JmOVHmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_test = last_hidden_states_test[0][:,0,:].numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GgrQcUhpqyyJ"
      },
      "source": [
        "The labels indicating which sentence is positive and negative now go into the `labels` variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V3rKmx5NqyyH",
        "colab": {}
      },
      "source": [
        "labels = batch_1['SentimentHeadline']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkzvUTGvSrUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OKi-E7zoqyyG"
      },
      "source": [
        "## Model #2: Train/Test Split\n",
        "Let's now split our datset into a training set and testing set (even though we're using 2,000 sentences from the SST2 training set)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v0a90lheqyyB",
        "colab": {}
      },
      "source": [
        "# parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
        "# grid_search = GridSearchCV(LogisticRegression(), parameters)\n",
        "# grid_search.fit(train_features, train_labels)\n",
        "\n",
        "# print('best parameters: ', grid_search.best_params_)\n",
        "# print('best scrores: ', grid_search.best_score_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w4uyFRbYqyyA"
      },
      "source": [
        "We now train the LogisticRegression model. If you've chosen to do the gridsearch, you can plug the value of C into the model declaration (e.g. `LogisticRegression(C=5.2)`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y2EYwogFqyx1"
      },
      "source": [
        "##RandomForest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5SAPCmvEqyxy"
      },
      "source": [
        "##XGboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WvoePjZSqyxu",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QYcu2vEgqyxs",
        "colab": {}
      },
      "source": [
        "X=features\n",
        "y=labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAaGaPj-WScX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_TEST=features_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2iG5w5h-qyxq",
        "colab": {}
      },
      "source": [
        "data_dmatrix = xgb.DMatrix(features,labels)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UfjtSwDNqyxo",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A5vxxknhqyxl",
        "colab": {}
      },
      "source": [
        "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 5, alpha = 10, n_estimators = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VFm3Xnxoqyxj",
        "outputId": "5a03c3fb-03d4-42f5-fa55-989a78d8fce5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "xg_reg.fit(X_train,y_train)\n",
        "\n",
        "preds = xg_reg.predict(X_test)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[06:36:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R--vbPavqyxg",
        "outputId": "0cabc172-0f0b-4682-bdbf-e8eca2003dac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "print(\"RMSE: %f\" % (rmse))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.239476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7Io23Ty2qyxA",
        "outputId": "13fc557d-8796-4563-f3c0-0893e29bbbb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "xg_reg1 = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 10, alpha = 10, n_estimators = 70)\n",
        "xg_reg1.fit(X_train,y_train)\n",
        "\n",
        "preds1 = xg_reg1.predict(X_test)\n",
        "rmse1 = np.sqrt(mean_squared_error(y_test, preds1))\n",
        "print(\"RMSE: %f\" % (rmse1))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[06:36:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "RMSE: 0.135742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzN-J9y4YfOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HENWpTRnpVVX",
        "colab_type": "text"
      },
      "source": [
        "##submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THK2P0Jk6yir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_1_test['SentimentHeadline'] = xg_reg1.predict(X_TEST)\n",
        "batch_1_test.to_csv('submission_headline.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMRcL-paCu4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vfcvphYGeHcO"
      },
      "source": [
        "#SentimentTitle prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZDuiLiEeawW",
        "colab_type": "code",
        "outputId": "62057cb3-69bb-46f1-e622-e6fb78e84389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/ZS/input/dataset/train_file.csv', sep=\",\")\n",
        "df.tail(2)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IDLink</th>\n",
              "      <th>Title</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Source</th>\n",
              "      <th>Topic</th>\n",
              "      <th>PublishDate</th>\n",
              "      <th>Facebook</th>\n",
              "      <th>GooglePlus</th>\n",
              "      <th>LinkedIn</th>\n",
              "      <th>SentimentTitle</th>\n",
              "      <th>SentimentHeadline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>55930</th>\n",
              "      <td>P0EBiaSEjq</td>\n",
              "      <td>Microsoft finally releases giant Surface</td>\n",
              "      <td>Microsoft’s business customers are finally beg...</td>\n",
              "      <td>TechEye</td>\n",
              "      <td>microsoft</td>\n",
              "      <td>2016-03-29 01:38:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.028296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55931</th>\n",
              "      <td>99MLvyAQTJ</td>\n",
              "      <td>Rays of sunshine in the US economy</td>\n",
              "      <td>AS WE all know from listening to the campaign ...</td>\n",
              "      <td>Washington Post</td>\n",
              "      <td>economy</td>\n",
              "      <td>2016-03-29 01:41:08</td>\n",
              "      <td>75</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.184444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           IDLink  ... SentimentHeadline\n",
              "55930  P0EBiaSEjq  ...         -0.028296\n",
              "55931  99MLvyAQTJ  ...          0.184444\n",
              "\n",
              "[2 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1agX5OudeHcR",
        "colab": {}
      },
      "source": [
        "batch_total = df[['Title', 'SentimentTitle']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uA9O6ltTeHcU",
        "colab": {}
      },
      "source": [
        "batch_1 = batch_total[:2000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fwu4WFoneHcW"
      },
      "source": [
        "## Loading the Pre-trained BERT model\n",
        "Let's now load a pre-trained BERT model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PawNOShweHcY",
        "colab": {}
      },
      "source": [
        "# For DistilBERT:\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "## Want BERT instead of distilBERT? Uncomment the following line:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "'''\n",
        "# Transformers has a unified API\n",
        "# for 10 transformer architectures and 30 pretrained weights.\n",
        "#          Model          | Tokenizer          | Pretrained weights shortcut\n",
        "MODELS = [(BertModel,       BertTokenizer,       'bert-base-uncased'),\n",
        "          (OpenAIGPTModel,  OpenAIGPTTokenizer,  'openai-gpt'),\n",
        "          (GPT2Model,       GPT2Tokenizer,       'gpt2'),\n",
        "          (CTRLModel,       CTRLTokenizer,       'ctrl'),\n",
        "          (TransfoXLModel,  TransfoXLTokenizer,  'transfo-xl-wt103'),\n",
        "          (XLNetModel,      XLNetTokenizer,      'xlnet-base-cased'),\n",
        "          (XLMModel,        XLMTokenizer,        'xlm-mlm-enfr-1024'),\n",
        "          (DistilBertModel, DistilBertTokenizer, 'distilbert-base-uncased'),\n",
        "          (RobertaModel,    RobertaTokenizer,    'roberta-base'),\n",
        "          (XLMRobertaModel, XLMRobertaTokenizer, 'xlm-roberta-base'),\n",
        "         ]\n",
        "\n",
        "# To use TensorFlow 2.0 versions of the models, simply prefix the class names with 'TF', e.g. `TFRobertaModel` is the TF 2.0 counterpart of the PyTorch model `RobertaModel`\n",
        "\n",
        "# Each architecture is provided with several class for fine-tuning on down-stream tasks, e.g.\n",
        "BERT_MODEL_CLASSES = [BertModel, BertForPreTraining, BertForMaskedLM, BertForNextSentencePrediction,\n",
        "                      BertForSequenceClassification, BertForTokenClassification, BertForQuestionAnswering]\n",
        "\n",
        "# All the classes for an architecture can be initiated from pretrained weights for this architecture\n",
        "# Note that additional weights added for fine-tuning are only initialized\n",
        "'''\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M-hmlUt1eHcb"
      },
      "source": [
        "Right now, the variable `model` holds a pretrained distilBERT model -- a version of BERT that is smaller, but much faster and requiring a lot less memory.\n",
        "\n",
        "## Model #1: Preparing the Dataset\n",
        "Before we can hand our sentences to BERT, we need to so some minimal processing to put them in the format it requires.\n",
        "\n",
        "### Tokenization\n",
        "Our first step is to tokenize the sentences -- break them up into word and subwords in the format BERT is comfortable with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rF9cOX_aeHcb"
      },
      "source": [
        "##tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4VkPEIkoeHcc",
        "colab": {}
      },
      "source": [
        "tokenized = batch_1['Title'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-DvfPj3DeHcf",
        "colab": {}
      },
      "source": [
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "#max_len = max(max_len,66) # to make it more understandable as our iamges have tokens of length 66\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dK3Dl-h6eHch"
      },
      "source": [
        "Our dataset is now in the `padded` variable, we can view its dimensions below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QgmNa06peHcj",
        "outputId": "aeb8eee4-291b-4740-8487-e550c4674212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(padded).shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tCJWB1dYeHcm",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "twQwu3PteHco",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "06sy8nv0eHcq",
        "colab": {}
      },
      "source": [
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "## Want BERT instead of distilBERT? Uncomment the following line:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "'''\n",
        "# Transformers has a unified API\n",
        "# for 10 transformer architectures and 30 pretrained weights.\n",
        "#          Model          | Tokenizer          | Pretrained weights shortcut\n",
        "MODELS = [(BertModel,       BertTokenizer,       'bert-base-uncased'),\n",
        "          (OpenAIGPTModel,  OpenAIGPTTokenizer,  'openai-gpt'),\n",
        "          (GPT2Model,       GPT2Tokenizer,       'gpt2'),\n",
        "          (CTRLModel,       CTRLTokenizer,       'ctrl'),\n",
        "          (TransfoXLModel,  TransfoXLTokenizer,  'transfo-xl-wt103'),\n",
        "          (XLNetModel,      XLNetTokenizer,      'xlnet-base-cased'),\n",
        "          (XLMModel,        XLMTokenizer,        'xlm-mlm-enfr-1024'),\n",
        "          (DistilBertModel, DistilBertTokenizer, 'distilbert-base-uncased'),\n",
        "          (RobertaModel,    RobertaTokenizer,    'roberta-base'),\n",
        "          (XLMRobertaModel, XLMRobertaTokenizer, 'xlm-roberta-base'),\n",
        "         ]\n",
        "\n",
        "# To use TensorFlow 2.0 versions of the models, simply prefix the class names with 'TF', e.g. `TFRobertaModel` is the TF 2.0 counterpart of the PyTorch model `RobertaModel`\n",
        "\n",
        "# Each architecture is provided with several class for fine-tuning on down-stream tasks, e.g.\n",
        "BERT_MODEL_CLASSES = [BertModel, BertForPreTraining, BertForMaskedLM, BertForNextSentencePrediction,\n",
        "                      BertForSequenceClassification, BertForTokenClassification, BertForQuestionAnswering]\n",
        "\n",
        "# All the classes for an architecture can be initiated from pretrained weights for this architecture\n",
        "# Note that additional weights added for fine-tuning are only initialized\n",
        "'''\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AbCUdwlceHcw",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ku3cYbqkeHcy",
        "colab": {}
      },
      "source": [
        "batch_total_test2 = df_test[['Title','IDLink']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X-pOFt58eHc0",
        "colab": {}
      },
      "source": [
        "batch_1_test2 = batch_total_test2[:1000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfMuI2_KiRRw",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mDFSLgDEeHc2",
        "colab": {}
      },
      "source": [
        "tokenized_test = batch_1_test2['Title'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-L9QDijJeHc5",
        "colab": {}
      },
      "source": [
        "max_len = 0\n",
        "for i in tokenized_test.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "#max_len = max(max_len,66) # to make it more understandable as our iamges have tokens of length 66\n",
        "padded_test = np.array([i + [0]*(max_len-len(i)) for i in tokenized_test.values])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zdrgBA6feHc8",
        "outputId": "67a97855-aeeb-402d-cbaf-38080589262b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(padded_test).shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8aqmTnYieHc-"
      },
      "source": [
        "### Masking\n",
        "If we directly send `padded` to BERT, that would slightly confuse it. We need to create another variable to tell it to ignore (mask) the padding we've added when it's processing its input. That's what attention_mask is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x3l5sWs0eHc_",
        "outputId": "c2fb009d-115a-41de-f911-df200b15b10a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5QtmGvu6eHdB",
        "outputId": "4f989a3b-9b0b-4ec2-8052-c0b262645c47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "attention_mask_test = np.where(padded_test != 0, 1, 0)\n",
        "attention_mask_test.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H3tN8LJdeHdE",
        "colab": {}
      },
      "source": [
        "input_ids = torch.tensor(padded)  \n",
        "attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CvJ6RN_XeHdH",
        "colab": {}
      },
      "source": [
        "input_ids_test = torch.tensor(padded_test)  \n",
        "attention_mask_test = torch.tensor(attention_mask_test)\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states_test = model(input_ids_test, attention_mask=attention_mask_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hxAVgP5yeHdJ",
        "colab": {}
      },
      "source": [
        "features = last_hidden_states[0][:,0,:].numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q0JpLsVGeHdL",
        "colab": {}
      },
      "source": [
        "features_test = last_hidden_states_test[0][:,0,:].numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ls26VEZKeHdS"
      },
      "source": [
        "The labels indicating which sentence is positive and negative now go into the `labels` variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cCk2KIEUeHdS",
        "colab": {}
      },
      "source": [
        "labels = batch_1['SentimentTitle']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bO1Lm0_HeHdU",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w38LJMTQeHdX"
      },
      "source": [
        "## Model #2: Train/Test Split\n",
        "Let's now split our datset into a training set and testing set (even though we're using 2,000 sentences from the SST2 training set)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MDjo5aLPeHdb",
        "colab": {}
      },
      "source": [
        "# parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
        "# grid_search = GridSearchCV(LogisticRegression(), parameters)\n",
        "# grid_search.fit(train_features, train_labels)\n",
        "\n",
        "# print('best parameters: ', grid_search.best_params_)\n",
        "# print('best scrores: ', grid_search.best_score_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7X3BlaypeHdd"
      },
      "source": [
        "We now train the LogisticRegression model. If you've chosen to do the gridsearch, you can plug the value of C into the model declaration (e.g. `LogisticRegression(C=5.2)`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vOpcDMBmeHdi"
      },
      "source": [
        "##XGboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zpcCpMD7eHdj",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0hSNbjOueHdm",
        "colab": {}
      },
      "source": [
        "X=features\n",
        "y=labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GenaSrwneHdo",
        "colab": {}
      },
      "source": [
        "X_TEST=features_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RjYHu5iveHdr",
        "outputId": "33c04179-088b-4e1b-bf11-3ac879a9a0b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(X_TEST)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XUrImzgieHdu",
        "colab": {}
      },
      "source": [
        "data_dmatrix = xgb.DMatrix(features,labels)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MILVlhraeHdw",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SbaIyGn7eHdz",
        "colab": {}
      },
      "source": [
        "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 5, alpha = 10, n_estimators = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B_57kgCIeHd1",
        "outputId": "8b44f27a-789f-4e70-81a8-8e6939613cc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "xg_reg.fit(X_train,y_train)\n",
        "\n",
        "preds = xg_reg.predict(X_test)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[06:39:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PJEh667oeHd3",
        "outputId": "abc81a55-3214-4154-9319-29d236fcda4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "print(\"RMSE: %f\" % (rmse))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.218313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NV0OJ-BZeHd-",
        "outputId": "2709ebc2-d73d-48c1-b3f2-b62d5e8529a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "xg_reg1 = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 10, alpha = 10, n_estimators = 70)\n",
        "xg_reg1.fit(X_train,y_train)\n",
        "\n",
        "preds1 = xg_reg1.predict(X_test)\n",
        "rmse1 = np.sqrt(mean_squared_error(y_test, preds1))\n",
        "print(\"RMSE: %f\" % (rmse1))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[06:39:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "RMSE: 0.118482\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w3jZ8AtXeHeA",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FfVMXPcWeHeI"
      },
      "source": [
        "##submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DMfpj25NeHeI",
        "outputId": "f1b1c2fd-617a-4a64-f189-480a1bb24994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "df_test = pd.read_csv('/content/drive/My Drive/ZS/input/dataset/sample_submission.csv', sep=\",\")\n",
        "df_test.tail(2)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IDLink</th>\n",
              "      <th>SentimentTitle</th>\n",
              "      <th>SentimentHeadline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lflGp3q2Fj</td>\n",
              "      <td>-0.073611</td>\n",
              "      <td>-0.417361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>zDYG0SoovZ</td>\n",
              "      <td>0.047111</td>\n",
              "      <td>-0.213201</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       IDLink  SentimentTitle  SentimentHeadline\n",
              "3  lflGp3q2Fj       -0.073611          -0.417361\n",
              "4  zDYG0SoovZ        0.047111          -0.213201"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dqMlYYPMeHeP",
        "colab": {}
      },
      "source": [
        "batch_1_test2['SentimentTitle'] = xg_reg1.predict(X_TEST)\n",
        "batch_1_test2.to_csv('submissionTitle.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfI5B3ESilBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17kG4B_2yZu5",
        "colab_type": "text"
      },
      "source": [
        "##merge two dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzBBhtkYy1cW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = pd.read_csv(\"submissionTitle.csv\")\n",
        "df2 = pd.read_csv(\"submission_headline.csv\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN7OxpkZB_gu",
        "colab_type": "code",
        "outputId": "8bf9f8bb-a4c9-4e99-db11-2c6ccbea148c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df1.tail()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Title</th>\n",
              "      <th>IDLink</th>\n",
              "      <th>SentimentTitle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>995</td>\n",
              "      <td>Watch Microsoft's Seeing AI help a blind perso...</td>\n",
              "      <td>jInx470K9I</td>\n",
              "      <td>-0.001126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>996</td>\n",
              "      <td>Microsoft aims at computing platforms of the f...</td>\n",
              "      <td>ERJGQkk9tI</td>\n",
              "      <td>0.001250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>997</td>\n",
              "      <td>VIDEO: Hands on with the Microsoft Hololens</td>\n",
              "      <td>uBRBuNnyKF</td>\n",
              "      <td>0.018405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>998</td>\n",
              "      <td>Hands-on (again) with the Microsoft HoloLens</td>\n",
              "      <td>AVnr6kSHwY</td>\n",
              "      <td>-0.002099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>999</td>\n",
              "      <td>Consumer confidence in UK economy hit by 'Brex...</td>\n",
              "      <td>MVCl0HBBuE</td>\n",
              "      <td>-0.092407</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  ... SentimentTitle\n",
              "995         995  ...      -0.001126\n",
              "996         996  ...       0.001250\n",
              "997         997  ...       0.018405\n",
              "998         998  ...      -0.002099\n",
              "999         999  ...      -0.092407\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQmfAGJBB_lO",
        "colab_type": "code",
        "outputId": "a9ce1849-993c-409c-cb48-23753cb6480b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df2.tail()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Headline</th>\n",
              "      <th>IDLink</th>\n",
              "      <th>SentimentHeadline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>995</td>\n",
              "      <td>In a span of two and a half hours, Microsoft p...</td>\n",
              "      <td>jInx470K9I</td>\n",
              "      <td>-0.032728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>996</td>\n",
              "      <td>Microsoft made a pitch Wednesday to developers...</td>\n",
              "      <td>ERJGQkk9tI</td>\n",
              "      <td>-0.043160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>997</td>\n",
              "      <td>Dave Lee examines the potential of Microsoft's...</td>\n",
              "      <td>uBRBuNnyKF</td>\n",
              "      <td>0.003347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>998</td>\n",
              "      <td>Earlier today, Microsoft announced that a free...</td>\n",
              "      <td>AVnr6kSHwY</td>\n",
              "      <td>0.036260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>999</td>\n",
              "      <td>Consumers have seen their confidence in the UK...</td>\n",
              "      <td>MVCl0HBBuE</td>\n",
              "      <td>-0.059417</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  ... SentimentHeadline\n",
              "995         995  ...         -0.032728\n",
              "996         996  ...         -0.043160\n",
              "997         997  ...          0.003347\n",
              "998         998  ...          0.036260\n",
              "999         999  ...         -0.059417\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj_8wdoCBGxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df1.merge(df2, on=\"IDLink\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHV1DTEsB8pN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=df[['IDLink','SentimentTitle','SentimentHeadline']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjG4ucqgCiDY",
        "colab_type": "code",
        "outputId": "8cc059f1-78f4-43f1-c20b-97e5a636debc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.tail()\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IDLink</th>\n",
              "      <th>SentimentTitle</th>\n",
              "      <th>SentimentHeadline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>jInx470K9I</td>\n",
              "      <td>-0.001126</td>\n",
              "      <td>-0.032728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>ERJGQkk9tI</td>\n",
              "      <td>0.001250</td>\n",
              "      <td>-0.043160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>uBRBuNnyKF</td>\n",
              "      <td>0.018405</td>\n",
              "      <td>0.003347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>AVnr6kSHwY</td>\n",
              "      <td>-0.002099</td>\n",
              "      <td>0.036260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>MVCl0HBBuE</td>\n",
              "      <td>-0.092407</td>\n",
              "      <td>-0.059417</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         IDLink  SentimentTitle  SentimentHeadline\n",
              "995  jInx470K9I       -0.001126          -0.032728\n",
              "996  ERJGQkk9tI        0.001250          -0.043160\n",
              "997  uBRBuNnyKF        0.018405           0.003347\n",
              "998  AVnr6kSHwY       -0.002099           0.036260\n",
              "999  MVCl0HBBuE       -0.092407          -0.059417"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMBjuPGkC0z3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baRnMI8hTWnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}